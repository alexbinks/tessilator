.. notes:
tessilator notes
================

This page lists provides notes about the methods and underlying assumptions made in the production of the tessilator.

Aperture photometry
-------------------
1. The zero-point TESS magnitude :math:`G_0 = 20.44 \pm 0.05` mag (`TESS instrument handbook <https://archive.stsci.edu/files/live/sites/mast/files/home/missions-and-data/active-missions/tess/_documents/TESS_Instrument_Handbook_v0.1.pdf>`_)
2. When performing aperture photometry, there are some cases where the background is actually brighter than source. Background-subtracted flux values, whilst not physically meaningful, may still be used to generate a lightcurve which can be used in Lomb-Scargle periodogram analyses. However, there are rare cases in which the raw flux (before background-subraction) values are negative. These are likely due to overestimated smear corrections when a bright/saturated star is very close to the top of the CCD and accumulates a large charge count in the smear correction. For the latter case we are unable to use these data.
3. The aperture radius can either be a set to a constant value (default 1.0 pixels), or is determined from an algorithm which uses the relative brightness of surrounding pixels. The latter case is set as default, whereby if the median brightness of the 8 pixels that neighbour the pixel centered on the target is greater than (a default value of) 0.25, the aperture radius is increased by one pixel, and the next outer square ring of pixel values are assessed, and so on, until either the criteria is not matched, or a maximum (default) radius of 3 pixels is reached.
4. The background flux is calculated using two annuli, with default values of 6.0 and 8.0 pixels centered on the target. To reduce computational time, the modal flux used to represent the background is calculated using Pearson's empirical relationship.

Contamination
-------------
1. The FWHM of the TESS point-spread function, :math:`T_{\rm PSF}` is assumed to be 0.65 pixels. This value is used for the calculation of flux contamination and was calculated by fitting Gaussians to 15 `TESS Pixel Response Functions <https://heasarc.gsfc.nasa.gov/docs/tess/observing-technical.html>`_ in a number of sector/camera/ccd configurations. The mean FWHM values from these fits are :math:`0.65 \pm 0.05`. In future releases we may implement a more rigorous method to calculate :math:`T_{\rm PSF}` by interpolating X/Y positions in these images, however, we are confident that :math:`T_{\rm PSF} = 0.65` is fairly constant and has little effect on the contamination calculation and no effect on the aperture photometry.
2. The default parameters to identify potential contaminants are a search radius of 5-pixels (:math:`105''`) of the target, and limited to sources with Gaia RP-band magnitudes brighter than 3 magnitudes fainter than the target. Whilst these are optimized values designed for a quick and efficient search, they are set as keywords, and be easily modified. The RP-band was chosen because the passband response function is very similar to that of TESS.
3. There are three basic parameters calculated from the flux contamination procedures. These are the number of potential contaminants within the given search radius, and the (logarithmic) ratio of flux captured within the aperture radius from both `all` contaminants, and the strongest contaminator, compared to that of the target. The analytic calculation to measure flux contamination is given by equation 3b-10 from `Biser & Millman (1965) <https://books.google.co.uk/books?id=5XBGAAAAYAAJ>`_.
4. If the user selects to run a periodogram analysis on possible contaminants, the tessilator will select (as a default), the 10 most significant contaminanting sources identified in the contamination functions. The idea is to run the tessilator on each contaminant and return a flag representing how likely it is that the period measured for the target, is in fact, that of a contaminating source. This may be modified in future releases to return a probability of unreliability rather than a discrete flag.

Lightcurve analyses
-------------------
1. The lightcurve uses the background-subtracted counts, calculated from the aperture photmetry routines, as the input for flux. Whilst magnitudes could be used, negative counts have indeterminate magnitude values and can't be used as data points.
2. In general, there are nine steps used to normalise, detrend and clean the lightcurves:
   a. Normalise the original flux points, by dividing these by the median value
   b. Split the lightcurve into groups, where groups are separated by time factors much larger than the median observing cadence.
   c. Remove very sparse groups, typically those with less than 50 datapoints.
   d. Run the detrending process to pass to the cleaning function. This step uses Aikake Information Criteria to determine whether the normalised fluxes should be detrended with a linear fit, and if so, whether the groups should be detrended individually, or as a full lightcurve. Parabolas, or higher-order polynomials, are not used because these may remove genuine periodic signals from the lightcurves. 
   e. Remove flux outliers from the edges of each group.
   f. Remove highly scattered fluxes from the edges of each group.
   g. Remove extreme outliers.
   h. Divide the detrended fluxes from each group by the median flux of (qualified datapoints) the group.
   i. Store all results from the full lightcurve analysis to a dictionary.
During the (removal) steps c, e, f and g procedure, a record of datapoints that are kept or rejected is made, allowing users to assess the amount of data loss. The reader is referred to the doc strings for additional information on each of these individual steps.

Accounting/Correcting for systematic noise
------------------------------------------
Systematic noise is unfortunately an all persisting issue with TESS lightcurves. Like any other space-based mission, TESS suffers from non-uniform instrument degradation, and the photometer is sensitive to scattered lunar and diurnal light. The tessilator has 3 different methods to (attempt to) remove systematic noise.
1. Applying the so-called Cotrending Basis Vectors (CBVs) provided by the `TESS SPOC <https://archive.stsci.edu/tess/bulk_downloads/bulk_downloads_cbv.html>`_. For a given sector, CCD and camera, the CBV vectors are designed to capture the lightcurve pattern caused by noise, as a function of X/Y pixel position. By taking the dot-product of the CBVs with the lightcurve flux, a noise-cleaned lightcurve is, in principle, produced. The tessilator comes with an option to apply the CBV corrections, however, user discretion is strongly advised. Overfitting CBVs can often lead to worse results than the original, which seems to become more problematic for targets with faint/low signal-to-noise lightcurves. If the CBV correction is selected, the results of the original and CBV-corrected lightcurve are assessed using a point scoring system, based on variety of lightcurve quality parameters (e.g., intrinsic scatter, number of outliers, etc). If the CBV lightcurve scores highest, a periodogram analysis is made for both lightcurves, and another point system based on the periodogram quality parameters is made to determine which set of results to use.
2. Dividing the lightcurve by a lightcurve which is generated by taking the median flux (at a given timestamp) of all lightcurves for targets with no clear periodic signal in a given sector/CCD/camera and within a certain Gaia G-band magnitude range. This method is still under construction, and is only partially available for certain sector/CCD/camera/G-magnitude configurations. Also, this method does not account for the X/Y pixel response, which may vary across the surface of each CCD.
3. Dividing the lightcurve by a lightcurve which is generated by taking the median flux (at a given timestamp) of all lightcurves from neighbouring, potential contaminant sources (identified during the contamination procedure) that have no clear periodic signal. Whilst this method gives a better approximation of the noise in the vicinity of the target, the method depends on a local region with enough identified potential contaminant sources, and does not filter out any targets, because there are generally not enough data to fill higher parameter spaces.
All 3 methods have their limitations, and it is very much down to the user to decide if they want to apply any of these corrections. If a noise correction is applied, it is vital that only ONE of the above methods is used. 

Lomb-Scargle periodograms
-------------------------
1. Periodograms are constructed using the "autopower" implementation in the `astropy timeseries module <https://docs.astropy.org/en/stable/timeseries/lombscargle.html#method-auto>`_. This method automatically attempts to select the best option of periodogram calculation using heuristics driven by the input data.
2. The minimum and maximum periods are default set as 0.05 and 100 days, respectively, where the lower-limit is set to ensure the sampling is above the Nyquist limit for 30-minute cadence, and the upper limit is a practical choice of 4 times the typical sector duration of ~25 days. The number of samples per peak is default set to 10, to ensure each data point is sampled enough times to provide a Gaussian fit to the peak power output. All these parameters are default values and can be modified by users.
3. False alarm probability values are calculated at 1, 5 and 10 per cent level.
4. The ``N``-highest peaks in the periodogram are located (default ``N`` = 4), and Gaussian fits made to provide a period measurement and uncertainty. This is calculated in practice by first removing the data points that construct the highest peak and then identifying the peak power output from this subset, and this process repeated for a specified number of times. The algorithm to remove data around the highest peak is essentially a "descent function" that keeps neighbouring points either side of the peak that descend in value until a neighbouring point results in an increase (see doc strings for more information).
5. For noisy lightcurves, the periodogram will often (erroneously) find a strong power output at either extremely short, or long periods (which is indicative of tracing the noise). Therefore, a option has been implemented that invokes a Monte-Carlo type procedure, where sections of the lightcurve are drawn at random, from which a period is measured. The idea is that if the period distribution peaks at a given value with a sufficiently small scatter, then the ''shuffled period'' is evaluated as the dominant period measurement. This method is clearly more sensitive towards targets with shorter periods, but allows the tessilator to measure periods for targets as faint as ``G~18``!
6. The lightcurve is phase-folded using the dominant period measurement. This information provides some parameters that can be used as quality criteria for the period measurement, such as the amplitude, typical scatter and number of extreme outliers in the phase-folded lightcurve. 
