TESSILATOR NOTES
================

This page lists provides notes about the assumptions and choices made in the production of the tessilator.

Contamination
-------------
1. The FWHM of the TESS point-spread function, :math:`T_{\rm PSF}` is assumed to be 0.65 pixels. This value is used for the calculation of flux contamination and was calculated by fitting Gaussians to 15 `TESS Pixel Response Functions <https://heasarc.gsfc.nasa.gov/docs/tess/observing-technical.html>`_ in a number of sector/camera/ccd configurations. The mean FWHM values from these fits are :math:`0.65 \pm 0.05`. In future releases we may implement a more rigorous method to calculate :math:`T_{\rm PSF}` by interpolating X/Y positions in these images, however, we are confident that :math:`T_{\rm PSF} = 0.65` is fairly constant and has little effect on the contamination calculation and no effect on the aperture photometry.
2. Potential contaminants are searched within a 5-pixel radius (:math:`105''`) of the target, and limited to sources with G-band magnitudes brighter than 3 magnitudes fainter than the target. Both these values are default values that can be modified, however, they are optimized values designed for a quick and efficient search.
3. If the user selects to run a periodogram analysis on possible contaminants, the tessilator will select as a default,  (up to) the 5 most significant contaminanting sources identified in the contamination functions. The idea is to run the tessilator on each contaminant and return a flag representing how likely it is that the period measured for the target, is in fact, that of a contaminating source. This may be modified in future releases to return a probability of unreliability rather than a discrete flag.

Aperture photometry
-------------------
1. The zero-point TESS magnitude :math:`G_0 = 20.44 \pm 0.05` mag (`TESS instrument handbook <https://archive.stsci.edu/files/live/sites/mast/files/home/missions-and-data/active-missions/tess/_documents/TESS_Instrument_Handbook_v0.1.pdf>`_)
2. When performing aperture photometry, there are some cases where the background is actually brighter than source. Background-subtracted flux values, whilst not physically meaningful, may still be used to generate a lightcurve which can be used in Lomb-Scargle periodogram analyses. However, there are rare cases in which the raw flux (before background-subraction) values are negative. These are likely due to overestimated smear corrections when a bright/saturated star is very close to the top of the CCD and accumulates a large charge count in the smear correction. For the latter case we are unable to use these data.
3. The aperture radius is set to a default of 1.0 pixels. This is close to the theoretical optimum for flux extraction in the sky-limited domain (`Naylor 1998 <https://ui.adsabs.harvard.edu/abs/1998MNRAS.296..339N/abstract>`_) and is suitable for point sources in both sparse and crowded regions. Users are able to alter the aperture radius, but should understand the rationale for doing so.
4. The background flux is calculated using two annuli, with default values of 6.0 and 8.0 pixels centered on the target. To reduce computational time, the modal flux used to represent the background is calculated using Pearson's empirical relationship.

Lightcurve analyses
-------------------
1. The lightcurve uses the background-subtracted counts as the input for flux. Whilst magnitudes could be used, negative counts have indeterminate magnitude values and can't be used as data points.
2. To remove extremities in the data, the initial step removes any points that are :math:`>20` (normalised) median absolute deviation values from the median number of counts in the lightcurve (:math:`=T_{\rm med}`). The data are normalised by dividing each point by :math:`T_{\rm med}`.
3. There are several features in TESS lightcurves that are artifacts of the instrument response rather than astronomical deteection -- these should be removed from the lightcurve analysis. To address this problem, we produced an algorithm that only keeps "packets" of data whose neighbouring data points are less than 10 times the median time difference between observations. The start and end points of these packets must have normalised flux values within 2.0 median absolute deviation of :math:`T_{\rm med}`, and there must be at least 50 data points in a packet. Each of these three parameters can be modified, but it is important users understand what these values represent and how it will affect the quality of the lightcurves.
4. Each packet of lightcurve data is detrended by either a linear or parabolic fit, which is determined using the Aikake Information Criterion.

Lomb-Scargle periodograms
-------------------------
1. Periodograms are constructed using the "autopower" implementation. This automatically attempts to select the best option of periodogram calculation using heuristics driven by the input data.
2. The minimum and maximum periods are 0.05 and 100. days, respectively. The number of samples per peak is set to 10, to ensure each data point is sampled enough times to provide a Gaussian fit to the peak power output. All these parameters are default values and can be modified by users.
3. False alarm probability values are calculated at 1, 5 and 10 per cent. Please refer to the `astropy documentation <https://docs.astropy.org/en/stable/timeseries/lombscargle.html#method-auto>`_ for a detailed description.
4. The second-highest peak is calculated by first removing the data points that construct the highest peak and then identifying the peak power output from this subset. The algorithm to remove data around the highest peak is essentially a "descent function" that keeps neighbouring points either side of the peak that descend in value until a neighbouring point results in an increase. Occasionally at longer periods, the peaks are quasi-Gaussian and can be "jagged" around the top. Therefore an extra criterion is made that the descent function is only implemented once a data point becomes :math:`<0.85` of the peak value.
5. To locate the central (period) value of the highest peak and to provide the measurement uncertainty, a Gaussian fit is applied to the data points that constitute the highest peak. To remove long tails, we set a criterion that only data representing the top 95 per cent are used in the fit. In the case where the highest peak corresponds to the minimum or maximum period value, the amplitude, mean and uncertainty of the Gaussian parameters are replaced by 1.0, (min/max) period and 50. This may be updated in future releases of the tessilator.
